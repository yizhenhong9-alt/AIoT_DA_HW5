import streamlit as st
import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from matplotlib import rcParams

# -------------------------------
# ä¸­æ–‡å­—å‹è¨­å®šï¼ˆé¿å…æ¡†æ¡†ï¼‰
# -------------------------------
rcParams['font.sans-serif'] = ['Microsoft JhengHei']  # Windows å¾®è»Ÿæ­£é»‘é«”
rcParams['axes.unicode_minus'] = False

# -------------------------------
# Streamlit é é¢è¨­å®š
# -------------------------------
st.set_page_config(page_title="AI / Human æ–‡ç« åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  AI / Human æ–‡ç« åµæ¸¬å™¨ (è‹±æ–‡æ–‡ç« å°ˆç”¨)")
st.markdown("""
æ­¤æ‡‰ç”¨ä½¿ç”¨ **sklearn TF-IDF + Logistic Regression** æ¨¡å‹ (`ai_detector.pkl`) ä¾†åˆ¤æ–·æ–‡ç« æ˜¯ **AIç”Ÿæˆ** é‚„æ˜¯ **Humanæ’°å¯«**ã€‚  

âš ï¸ **æ³¨æ„äº‹é …**ï¼š
- æœ¬æ¨¡å‹å°è‹±æ–‡æ–‡ç« æ•ˆæœæœ€ä½³ï¼Œè«‹å‹¿ä¸Šå‚³ä¸­æ–‡æ–‡ç« ã€‚
- å–®ç¯‡æ–‡ç« æª¢æ¸¬å¯ç›´æ¥è¼¸å…¥æ–‡å­—ã€‚
- æ‰¹æ¬¡æª¢æ¸¬å¯ä¸Šå‚³ **ç´”æ–‡å­—æª”ï¼ˆ.txtï¼‰**ï¼Œæ¯ç¯‡æ–‡ç« ä»¥æ›è¡Œåˆ†éš”ã€‚
- ä¸‹æ–¹æä¾›æ¨¡å‹ä¿¡å¿ƒåˆ†æï¼Œå¯è¦–åŒ–æ¸¬è©¦é›†ä¿¡å¿ƒåˆ†å¸ƒã€‚
""")

# -------------------------------
# è¼‰å…¥æ¨¡å‹
# -------------------------------
@st.cache_resource
def load_model():
    model = joblib.load("model/ai_detector.pkl")
    return model

model = load_model()

# -------------------------------
# å–®ç¯‡æ–‡ç« æª¢æ¸¬
# -------------------------------
st.subheader("âœï¸ å–®ç¯‡æ–‡ç« æª¢æ¸¬")
text = st.text_area("è«‹è¼¸å…¥è‹±æ–‡æ–‡ç« ï¼š", height=200)

if st.button("æª¢æ¸¬å–®ç¯‡æ–‡ç« "):
    if text.strip() == "":
        st.warning("è«‹è¼¸å…¥æ–‡ç« å…§å®¹")
    else:
        pred = model.predict([text])[0]
        prob = model.predict_proba([text])[0][1]

        label = "ğŸ¤– AI ç”Ÿæˆ" if pred == 1 else "ğŸ§‘ Human æ’°å¯«"
        st.subheader(f"é æ¸¬çµæœï¼š{label}")
        st.metric("AI æ©Ÿç‡", f"{prob:.2%}")

# -------------------------------
# æ‰¹æ¬¡æ–‡ç« æª”æ¡ˆä¸Šå‚³ï¼ˆè‹±æ–‡æ–‡ç« ï¼‰
# -------------------------------
st.subheader("ğŸ“„ æ‰¹æ¬¡æ–‡ç« æª¢æ¸¬ï¼ˆä¸Šå‚³ .txt æª”ï¼Œæ¯ç¯‡æ–‡ç« ä¸€è¡Œï¼‰")
uploaded_file = st.file_uploader("ä¸Šå‚³ç´”æ–‡å­—æª”", type=["txt"])

if uploaded_file is not None:
    content = uploaded_file.read().decode("utf-8")
    articles = [line.strip() for line in content.split("\n") if line.strip() != ""]
    if len(articles) == 0:
        st.warning("æª”æ¡ˆä¸­æ²’æœ‰æœ‰æ•ˆæ–‡ç« ")
    else:
        preds = model.predict(articles)
        probs = model.predict_proba(articles)[:, 1]

        df_result = pd.DataFrame({
            "æ–‡ç« å…§å®¹": articles,
            "é æ¸¬çµæœ": ["AI" if p==1 else "Human" for p in preds],
            "AI æ©Ÿç‡": [f"{p:.2%}" for p in probs]
        })

        st.markdown("### æ‰¹æ¬¡æª¢æ¸¬çµæœ")
        st.dataframe(df_result)

        # ä¸‹è¼‰çµæœ CSV
        csv = df_result.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="ä¸‹è¼‰çµæœ CSV",
            data=csv,
            file_name="batch_result.csv",
            mime="text/csv"
        )
